{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import sys\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "home_directory = os.path.expanduser('~')\n",
    "onedrive_folder_name = 'OneDrive'\n",
    "onedrive_path = os.path.join(home_directory, onedrive_folder_name)\n",
    "\n",
    "root = os.path.join(onedrive_path, 'CODES', 'samples', 'cifar10_data')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=root, download=True, train=True, transform=transform)\n",
    "cifar10_test = datasets.CIFAR10(root=root, download=True, train=False, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(cifar10_train, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(cifar10_test, batch_size=100, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_kernels(image, kernel_size):\n",
    "    \"\"\"\n",
    "    画像を kernel_size x kernel_size のパッチに分割\n",
    "    返り値のサイズ: (b, n_patches, c, kernel_size, kernel_size)\n",
    "    \"\"\"\n",
    "    b, c, h, w = image.shape\n",
    "    assert (h % kernel_size == 0) and (w % kernel_size == 0), \"Image size must be divisible by kernel size\"\n",
    "    patches = image.unfold(2, kernel_size, kernel_size).unfold(3, kernel_size, kernel_size)\n",
    "    patches = patches.contiguous().view(b, c, -1, kernel_size, kernel_size)\n",
    "    patches = patches.permute(0, 2, 1, 3, 4)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, kernel_size, leverage, channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.leverage = leverage\n",
    "\n",
    "        # 入力次元: c * (k*k)\n",
    "        self.kernel_in = (kernel_size ** 2) * channels\n",
    "        # 出力次元: kernel_in / leverage\n",
    "        self.output_dim = int(self.kernel_in / leverage)\n",
    "\n",
    "        # ランダムな位相の複素行列 B を作成\n",
    "        phase = torch.rand(self.output_dim, self.kernel_in) * 2 * np.pi - np.pi\n",
    "        modulus = torch.ones(self.output_dim, self.kernel_in)\n",
    "        real_part = modulus * torch.cos(phase)\n",
    "        imag_part = modulus * torch.sin(phase)\n",
    "\n",
    "        self.B = torch.complex(real_part, imag_part).detach().to(device)\n",
    "        self.B.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        xの形状: (b, n_patches, c, k, k)\n",
    "        \"\"\"\n",
    "        b, n_patches, c, kh, kw = x.shape\n",
    "        #alpha = torch.rand(1).item() * 0.5 + 0.5\n",
    "        alpha = torch.rand(self.kernel_in).to(x.device) * 0.5 + 0.5\n",
    "        x = x.reshape(b * n_patches, c * kh * kw)\n",
    "        x = torch.exp(1j * alpha * x) \n",
    "        x = x.T \n",
    "        x = torch.matmul(self.B, x)\n",
    "        x = x.T\n",
    "        x = torch.abs(x) ** 2  \n",
    "        return x , n_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_patches, feat_dim, num_classes, embed_dim=8, num_layers=2, num_heads=1, dropout=0.1):\n",
    "        \"\"\"\n",
    "        num_patches: 画像パッチ数\n",
    "        feat_dim: Encoder出力の次元\n",
    "        embed_dim: Transformerの内部表現の次元\n",
    "        num_layers: Transformer Encoderの層数\n",
    "        num_heads: マルチヘッド数\n",
    "        \"\"\"\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        # Encoder出力とTransformer入力の次元合わせ\n",
    "        self.proj = nn.Linear(feat_dim, embed_dim)\n",
    "        # 学習可能な位置埋め込み\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # 最終の分類ヘッド\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # xの形状: (b, n_patches, feat_dim)\n",
    "        x = self.proj(x)  # (b, n_patches, embed_dim)\n",
    "        x = x + self.pos_embed  # 位置埋め込みの追加\n",
    "        \n",
    "        x = self.transformer_encoder(x)  # (b, n_patches, embed_dim)\n",
    "        \n",
    "        # シンプルに各トークンの平均を取って集約\n",
    "        x = x.mean(dim=1)  # (b, embed_dim)\n",
    "        x = self.mlp_head(x)  # (b, num_classes)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(self, img_size, channels, kernel_size, leverage, num_classes=10):\n",
    "        super(EncoderClassifier, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.channels = channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.leverage = leverage\n",
    "\n",
    "        kernel_in = channels * kernel_size ** 2\n",
    "        feat_dim = int(kernel_in / leverage)\n",
    "        n_patches = (img_size // kernel_size) * (img_size // kernel_size)\n",
    "\n",
    "        self.split = split_into_kernels\n",
    "        self.encoder = Encoder(kernel_size, leverage, channels)\n",
    "        self.bn = nn.BatchNorm1d(feat_dim)  # 1次元のバッチ正規化（パッチごとの特徴に対して）\n",
    "        # ここで出力は (b, n_patches, feat_dim) となる\n",
    "        self.classifier = TransformerClassifier(n_patches, feat_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b = x.size(0)\n",
    "        x = x.view(b, self.channels, self.img_size, self.img_size)\n",
    "        x = self.split(x, self.kernel_size)  # (b, n_patches, c, k, k)\n",
    "        x, n_patches = self.encoder(x)       # Encoder出力: (b*n_patches, feat_dim)\n",
    "        x = self.bn(x)                       # バッチ正規化（ここでは1次元正規化）\n",
    "        # 後でTransformerの入力とするため、(b, n_patches, feat_dim)にリシェイプ\n",
    "        x = x.view(b, n_patches, -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n",
      "1/5th Time Epoch: 1/20"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m loss_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m start_time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 35\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torchvision/datasets/cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/anaconda3/envs/konishi000_res/lib/python3.11/site-packages/torchvision/transforms/functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    167\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(pic, mode_to_nptype\u001b[38;5;241m.\u001b[39mget(pic\u001b[38;5;241m.\u001b[39mmode, np\u001b[38;5;241m.\u001b[39muint8), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "channels = 3\n",
    "img_size = 32\n",
    "leverage = 8\n",
    "kernel_size = 4\n",
    "\n",
    "max_epochs = 20##10\n",
    "\n",
    "num_try = 5##5\n",
    "\n",
    "All_last_loss = []\n",
    "All_loss_test = []\n",
    "All_pro_time = []\n",
    "All_test_acc = []\n",
    "\n",
    "for num_times in range(num_try): \n",
    "\n",
    "    model = EncoderClassifier(img_size,channels, kernel_size, leverage).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    loss_train_ = []\n",
    "    loss_test_ = []\n",
    "    pro_time_ = []\n",
    "\n",
    "            \n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        sys.stderr.write('\\r%d/%dth Time Epoch: %d/%d' % (num_times+1,num_try, epoch+1, max_epochs)) \n",
    "        sys.stderr.flush()\n",
    "\n",
    "        loss_train = 0\n",
    "        loss_test = 0\n",
    "\n",
    "        start_time1 = time.time()\n",
    "        for (x,t) in train_dataloader:\n",
    "                    \n",
    "            x, t = x.to(device), t.to(device)\n",
    "            y = model(x).to(device)\n",
    "            loss = criterion(y, t) \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "       \n",
    "        loss_train_avg = loss_train / len(train_dataloader)\n",
    "        end_time1 = time.time()\n",
    "        pro_time_.append(end_time1-start_time1)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            first_batch = True\n",
    "            for x, t in test_dataloader:\n",
    "                x, t = x.to(device), t.to(device)\n",
    "                y = model(x).to(device)\n",
    "                _, predicted = torch.max(y, 1)\n",
    "                loss = criterion(y,t)\n",
    "                loss_test += loss.item()        \n",
    "                total += t.size(0)\n",
    "                correct += (predicted == t).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(t.cpu().numpy()) \n",
    "\n",
    "                if epoch == max_epochs - 1:\n",
    "                    if first_batch:\n",
    "                        x_splitted = model.split(x, kernel_size)\n",
    "                        x_in_flat = x_splitted.reshape(-1).detach().cpu().numpy()\n",
    "                        x_encoded, _ = model.encoder(x_splitted)\n",
    "                        x_out_flat = x_encoded.reshape(-1).detach().cpu().numpy()\n",
    "\n",
    "                        # サブプロットで横に並べて表示\n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "                        # 入力ヒストグラム\n",
    "                        axes[0].hist(x_in_flat, bins=20, color='darkorange', alpha=0.7)\n",
    "                        axes[0].set_xlabel(\"Input value\", fontsize=14)\n",
    "                        axes[0].set_ylabel(\"Frequency\", fontsize=14)\n",
    "                        axes[0].set_title(\"Input x Histogram\", fontsize=14)\n",
    "                        axes[0].tick_params(labelsize=12)\n",
    "                        axes[0].set_ylim(0,60000)\n",
    "\n",
    "                        # エンコーダ出力ヒストグラム\n",
    "                        axes[1].hist(x_out_flat, bins=20, color='steelblue', alpha=0.7)\n",
    "                        axes[1].set_xlabel(\"Encoder Output value\", fontsize=14)\n",
    "                        axes[1].set_ylabel(\"Frequency\", fontsize=14)\n",
    "                        axes[1].set_title(\"Encoder Output Histogram\", fontsize=14)\n",
    "                        axes[1].tick_params(labelsize=12)\n",
    "\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "\n",
    "                        first_batch = False\n",
    "\n",
    "        #print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "        loss_test_avg = loss_test / len(test_dataloader)\n",
    "\n",
    "        loss_train_.append(loss_train_avg)\n",
    "        loss_test_.append(loss_test_avg)\n",
    "        #if epoch == max_epochs-1:\n",
    "    All_loss_test.append(loss_test_)\n",
    "    All_pro_time.append(sum(pro_time_)) \n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)  # 正規化（行ごとに割合に）\n",
    "\n",
    "    Last_loss_test = loss_test_[-1]\n",
    "    All_last_loss.append(Last_loss_test)\n",
    "    Test_acc = 100 * correct / total\n",
    "    All_test_acc.append(Test_acc)\n",
    "    print(f\"Test Accuracy: {Test_acc:.2f}%\")\n",
    "    print(f\"loss_train: {loss_train_avg:.4f},loss_test: {loss_test_avg:.4f}\")\n",
    "    print(f\"LOSS:{Last_loss_test:.4f}\")\n",
    "    print('ProcessingTime:',sum(pro_time_))\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                    'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names,vmin=0.0, vmax=1.0)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(f\"Overall Correction Rate: {Test_acc:.2f}%\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(range(1,len(loss_train_)+1), loss_train_, label=\"Train LOSS\", color = 'blue')\n",
    "    ax1.plot(range(1,len(loss_test_)+1), loss_test_, label=\"Test LOSS\", color = 'cyan')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('LOSS', color = 'blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.legend()\n",
    "\n",
    "    title = 'LOSS: %dth Time'%(num_times+1) #\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Average  Best ID      Best  Worst ID      Worst\n",
      "0   ACC  56.452000        4  58.11000         2  54.720000\n",
      "1  LOSS   1.223179        4   1.19089         2   1.276346\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "ACC_mean = np.mean(All_test_acc)\n",
    "ACC_best = np.max(All_test_acc)\n",
    "ACC_bestID = np.argmax(All_test_acc)+1\n",
    "ACC_worst = np.min(All_test_acc)\n",
    "ACC_worstID = np.argmin(All_test_acc)+1\n",
    "\n",
    "LOSS_mean = np.mean(All_last_loss)\n",
    "LOSS_best = np.min(All_last_loss)\n",
    "LOSS_bestID = np.argmin(All_last_loss)+1\n",
    "LOSS_worst = np.max(All_last_loss)\n",
    "LOSS_worstID = np.argmax(All_last_loss)+1\n",
    "\n",
    "data = {\n",
    "        \"\": [\"ACC\", \"LOSS\"],\n",
    "    \"Average\": [ACC_mean, LOSS_mean],\n",
    "    \"Best ID\": [ACC_bestID, LOSS_bestID],\n",
    "    \"Best\": [ACC_best, LOSS_best],\n",
    "    \"Worst ID\": [ACC_worstID, LOSS_worstID],\n",
    "    \"Worst\": [ACC_worst, LOSS_worst],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(All_loss_test[0])  # エポック数（各リストの長さ）\n",
    "num_dimensions = len(All_loss_test)  # 埋め込み次元数の数\n",
    "\n",
    "# 各エポックごとに平均と標準偏差を計算\n",
    "mean_loss = np.mean(All_loss_test, axis=0)\n",
    "std_loss = np.std(All_loss_test, axis=0)\n",
    "\n",
    "# グラフの描画\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# 平均値の折れ線グラフと誤差範囲（標準偏差の誤差棒）\n",
    "ax1.errorbar(\n",
    "    x=range(1, epochs + 1), y=mean_loss, yerr=std_loss,\n",
    "    fmt='-o', color='blue', ecolor='blue', capsize=5, \n",
    ")\n",
    "\n",
    "# 軸ラベルやタイトルの設定\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('LOSS', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "plt.title('LOSS Transition in Test data')\n",
    "plt.ylim(1.0,2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/konishi/OneDrive/CODES/konishi_Classifer/data/texts\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "save_directory1 = os.path.join(onedrive_path,'CODES', 'konishi_Classifer', 'data','texts') \n",
    "print(save_directory1)\n",
    "os.makedirs(save_directory1, exist_ok=True)\n",
    "file_name = 'cifar10_CNN_PM_Class00_list.csv'##\n",
    "full_path = os.path.join(save_directory1, file_name)\n",
    "with open(full_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerow(All_loss_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "konishi000_res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
